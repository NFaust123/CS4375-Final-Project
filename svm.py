# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QK7Z_8LRt9GG-dnJwlvgGBNlCkc94Nf9
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
from scipy import stats

import sklearn
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_blobs
from sklearn import svm
from sklearn.svm import SVC # "Support vector classifier"
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV

"""# **CLEANING DATASET**"""

df = pd.read_csv("/content/drive/MyDrive/CS 4375 INTRO TO ML/CS 4375 FINAL PROJECT/diabetes_dataset__2019.csv")
df

df.describe()
df.info()

# Renaming columns with incorrect spelling

df.rename(columns={"Pregancies" : "Pregnancies", "UriationFreq" : "UrinationFrequency", "Pdiabetes" : "GestationDiabetes"}, inplace=True)
df

# getting total NA values for each column

df.isna().sum()

# for removing rows with NA values (BMI 4, GestationDiabetes 1, Diabetic 1)

na_indices = df[df['Diabetic'].isna() | df['GestationDiabetes'].isna() | df['BMI'].isna()].index.to_list()

print(na_indices)
df.drop(index= na_indices,inplace = True)

# checking if all rows with NA values were dropped

na_indices = df[df['Diabetic'].isna() | df['GestationDiabetes'].isna() | df['BMI'].isna()].index.to_list()

print(na_indices)

df.info()

# Checking values of "Pregnancies"
print(df.Pregnancies.unique())
print(df['Pregnancies'].value_counts())

# Changing NA values in "Pregnancies" to 0

df['Pregnancies'].fillna(value = 0.0, inplace= True)

print(df['Pregnancies'].value_counts())

# Changing type to int instead of float
df['Pregnancies'] = df['Pregnancies'].astype(int)
df['Pregnancies']

# Checking if we need to change any other values in dataset
for col in df:
  print(col)
  print(df[col].unique())

  # need to change
  # RegularMedicine ['no' 'yes' 'o']
  # BPLevel ['high' 'normal' 'low' 'Low' 'High' 'normal ']
  # GestationDiabetes ['0' 'yes' 'no']
  # Diabetic ['no' 'yes' ' no']

# original value counts before changes
changeCols = ["RegularMedicine", "BPLevel", "GestationDiabetes", "Diabetic"]
for col in changeCols:
  print(df[col].value_counts())

df["RegularMedicine"].replace('o', 'no', inplace =True)

df["BPLevel"].replace('High', 'high', inplace =True)
df["BPLevel"].replace('Low', 'low', inplace =True)
df["BPLevel"].replace('normal ', 'normal', inplace =True)

df["GestationDiabetes"].replace('0', 'no', inplace =True)
df["Diabetic"].replace(' no', 'no', inplace =True)

# checking if changes applied
changeCols = ["RegularMedicine", "BPLevel", "GestationDiabetes", "Diabetic"]
for col in changeCols:
  print(df[col].value_counts())

# Changing Gender values
df['Gender'].replace(to_replace = ['Male', 'Female'], value = [0, 1], inplace = True)

# Changing Family_Diabetes
df['Family_Diabetes'].replace(to_replace = ['no', 'yes'], value = [0, 1], inplace = True)

# Changing highBP
df['highBP'].replace(to_replace = ['no', 'yes'], value = [0, 1], inplace = True)

# Changing Smoking
df['Smoking'].replace(to_replace = ['no', 'yes'], value = [0, 1], inplace = True)

# Changing Smoking
df['Alcohol'].replace(to_replace = ['no', 'yes'], value = [0, 1], inplace = True)

# Changing regular medicine
df['RegularMedicine'].replace(to_replace = ['no', 'yes'], value = [0, 1], inplace = True)

# Changing GestationDiabetes
df['GestationDiabetes'].replace(to_replace = ['no', 'yes'], value = [0, 1], inplace = True)

# Changing UrinationFrequency
df['UrinationFrequency'].replace(to_replace = ['not much', 'quite often'], value = [0, 1], inplace = True)

# Changing diabetic
df['Diabetic'].replace(to_replace = ['no', 'yes'], value = [0, 1], inplace = True)

df.info()
df

# Getting dummy indicator variables from categorical variables

# Age
Age_dummies = pd.get_dummies(df['Age'], dtype = int, prefix='Age')
df.drop(['Age'], axis = 1, inplace=True)
df = pd.concat([df, Age_dummies], axis = 1)

# Physically Active
PhysicallyActive_dummies = pd.get_dummies(df['PhysicallyActive'], dtype = int, prefix='PhysicallyActive')
df.drop(['PhysicallyActive'], axis = 1, inplace=True)
df = pd.concat([df, PhysicallyActive_dummies], axis = 1)

# JunkFood
JunkFood_dummies = pd.get_dummies(df['JunkFood'], dtype = int, prefix='JunkFood')
df.drop(['JunkFood'], axis = 1, inplace=True)
df = pd.concat([df, JunkFood_dummies], axis = 1)

# Stress
Stress_dummies = pd.get_dummies(df['Stress'], dtype = int, prefix='Stress')
df.drop(['Stress'], axis = 1, inplace=True)
df = pd.concat([df, Stress_dummies], axis = 1)

# BPLevel
BPLevel_dummies = pd.get_dummies(df['BPLevel'], dtype = int, prefix='BPLevel')
df.drop(['BPLevel'], axis = 1, inplace=True)
df = pd.concat([df, BPLevel_dummies], axis = 1)

# dropping highBP
df.drop(['highBP'], axis = 1, inplace=True)

# Checking if there are any males that have values other than 0 for Pregnancies and GestationDiabetes

male_and_gestation = df[(df['Gender']==0) & (df['GestationDiabetes']==1)]  # found one at index 115, need to remove
df.drop((male_and_gestation).index, inplace = True)

### 12 OBSERVATIONS WITH MALE AND PREGNANT --------------------------------------------------------------------------------------------------------DECIDE TO DELETE OR NOT
df[(df['Gender']==0) & (df['Pregnancies']!=0)]

df.info()

"""# **TRAIN/TEST SPLIT**"""

X = df.drop('Diabetic', axis=1)
y = df['Diabetic']

# Train - Test Split

# random_state=0 allows for data to be split the same way each time (reproducible)
# stratify=y_train ---> training and testing data both have approx. same portion of diabetic and non-diabetic patients.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify= y)

# split for training and validation data
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=0, stratify=y_train)


scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
# print("With Standard Scaler X_Train")
# print(X_train)

X_test = scaler.fit_transform(X_test)
# print("\nWith Standard Scaler X_Test")
# print(X_test)

X_validation = scaler.fit_transform(X_validation)
# print("\nWith Standard Scaler X_validation")
# print(X_validation)

print(y_train.value_counts())
print(y_validation.value_counts())
print(y_test.value_counts())
X_train.shape , X_test.shape , X_validation.shape

"""# **SVM**

## **rbf Kernel**
 the RBF kernel is often used in classification tasks with a large number of features.
"""

# RBF KERNEL

# training model with training data
model = SVC(kernel = "rbf")
model.fit(X_train, y_train)

"""### VALIDATION DATA (BEFORE GRIDSEARCH)"""

# Predictions for Validation Data

y_pred_validation = model.predict(X_validation)

# confusion matrix
validation_matrix = confusion_matrix(y_validation, y_pred_validation)
print("Accuracy Score: ", accuracy_score(y_validation, y_pred_validation))

print("\nClassification report for validation set: \n")
print(classification_report(y_validation, y_pred_validation))

sns.heatmap(validation_matrix,
            annot=True,
            fmt='g',
            xticklabels=['Diabetic', 'Not Diabetic'],
            yticklabels=['Diabetic', 'Not Diabetic'])
plt.ylabel('Prediction', fontsize=13)
plt.xlabel('Actual', fontsize=13)
plt.title('Confusion Matrix for Validation Set', fontsize=15)
plt.show()

"""### GRIDSEARCH"""

model = SVC(kernel = "rbf")
model.fit(X_train, y_train)

param_grid = [
  {'C': [0.1,1,10,100], 'gamma': [0.01,0.001], 'kernel': ['rbf','sigmoid']},
 ]

grid = GridSearchCV(model,param_grid=param_grid, cv=10, n_jobs=-1)

grid.fit(X_train,y_train)

# not really sure what to do w this tbh

def cparameter(i):
    model = SVC(kernel='rbf',C=i)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    matrix = confusion_matrix(y_test, y_pred)
    print(accuracy_score(y_test, y_pred))
    print (matrix)

l = [0.1,1,10]
for i in l:
    print("\nfor the value of c = ", i)
    cparameter(i)

y_pred_validation_grid = grid.predict(X_validation)
# print(y_pred_validation_grid)

# confusion matrix
validation_matrix = confusion_matrix(y_validation, y_pred_validation_grid)

print(accuracy_score(y_validation, y_pred_validation_grid))

print("Classification report after tuning parameters: ")
print(classification_report(y_validation, y_pred_validation_grid))

print("Accuracy Score: ", accuracy_score(y_validation, y_pred_validation_grid))

print('\nTrue Positives(TP) = ', validation_matrix[0,0])
print('\nTrue Negatives(TN) = ', validation_matrix[1,1])
print('\nFalse Positives(FP) = ', validation_matrix[0,1])
print('\nFalse Negatives(FN) = ', validation_matrix[1,0])

sns.heatmap(validation_matrix,
            annot=True,
            fmt='g',
            xticklabels=['Diabetic', 'Not Diabetic'],
            yticklabels=['Diabetic', 'Not Diabetic'])
plt.ylabel('Prediction', fontsize=13)
plt.xlabel('Actual', fontsize=13)
plt.title('Confusion Matrix for Validation Set', fontsize=15)
plt.show()

print("Best Score: ", grid.best_score_)
print("Best parameters: ", grid.best_params_)
print("Best estimator: ", grid.best_estimator_)

"""### TESTING DATA"""

y_pred_test = grid.predict(X_test)

print("Classification Report for Test Set: ")
print(classification_report(y_test, y_pred_test))

# confusion matrix
test_matrix = confusion_matrix(y_test, y_pred_test)

print("Accuracy Score: ", accuracy_score(y_test, y_pred_test))

print('\nTrue Positives(TP) = ', test_matrix[0,0])
print('\nTrue Negatives(TN) = ', test_matrix[1,1])
print('\nFalse Positives(FP) = ', test_matrix[0,1])
print('\nFalse Negatives(FN) = ', test_matrix[1,0])

sns.heatmap(test_matrix,
            annot=True,
            fmt='g',
            xticklabels=['Diabetic', 'Not Diabetic'],
            yticklabels=['Diabetic', 'Not Diabetic'])
plt.ylabel('Prediction', fontsize=13)
plt.xlabel('Actual', fontsize=13)
plt.title('Confusion Matrix for Test Set', fontsize=15)
plt.show()

accuracy_validation = accuracy_score(y_validation, y_pred_validation)
precision_validation = precision_score(y_validation, y_pred_validation)
recall_validation = recall_score(y_validation, y_pred_validation)

print("Validation Set Metrics:")
print("Accuracy:", accuracy_validation)
print("Precision:", precision_validation)
print("Recall:", recall_validation)

"""## **Without Linear Kernel**"""